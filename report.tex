\documentclass[b5paper]{report}

\usepackage{color}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{svg}
\usepackage{float}
\usepackage{url}
\usepackage{parskip}
\usepackage[chapter]{minted}

\graphicspath{{images/}}
\svgpath{{images/}}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,decorations,shadows}

\begin{document}
\title{Efficient recovery in a data-flow based storage system}
\author{Martin Ek}
\date{\today}
\maketitle

\input{macros.tex}

\begin{abstract}
  Abstract
\end{abstract}

\tableofcontents
\pagebreak

\chapter{Introduction}
Soup is a high-performance database system developed at the Parallel and
Distributed Operating System group at MIT CSAIL. Soup builds up and maintains a
data-flow graph, avoiding the need to manually maintain materialized views. By
adapting the graph to schema changes on-the-fly, Soup avoids the substantial
downtime that comes with migrations in traditional relational database
management systems.

Utilizing a group-commit protocol, Soup persists all base table writes to
a log on durable storage before propagating changes throughout the graph.
Recovery is based on replaying the semantic updates in this log, which naturally
leads to gradually increasing recovery times as a database acquires more data.
Checkpointing by taking a snapshot of the database's current state is a common
way to solve this issue, reducing the size of the log at the same time. This is
not trivial in Soup however, where the data is spread across materializations in
the data-flow graph, and updates are propagated through asynchronously without
timestamps.

This thesis approaches the problem of creating a logically consistent snapshot
across Soup's data-flow graph by comparing it to a distributed system, where
each node in the graph can be seen as a node in a distributed setting. Soup as a
system is introduced in Chapter 2, whereas Chapter 3 looks at and compares
recovery solutions in different database systems before going into more detail
regarding Soup's solution for recovery. Then, various solutions for
snapshotting in distributed systems are investigated, while parallels to Soup's
own data-flow graph are drawn. Finally, a method for snapshotting in Soup is
proposed, implemented and compared to the baseline of only log based recovery.

\chapter{Background}
\section{Soup}
Modern web applications face an increasingly difficult performance problem in
relation to their storage needs: traditional relational databases perform too
poorly when used in isolation. Either by failing to scale to a large amount of
concurrent users, or by taking too long to return results for more expensive
aggregation queries.

This is often worked around by building up intricate cache hierarchies
\cite{memcached}, similar to the multi-level cache hierarchy readers might be
accustomed to seeing in their processors. This solves both performance problems:
concurrent readers can access materialized data from the upper levels of the
cache hierarchy, achieving low latency and high throughput even when faced with
large amounts of clients. Expensive queries then only need to be performed once,
as long as the result is invalidated when the underlying data changes. Write
operations still need to change the underlying storage layer however, but are
now also responsible for clearing out or updating the materialized cache levels.

This adds an extra layer of complexity, and is a trade-off accepted by almost
every modern day developer that faces more than a trivial amount of load to
their storage system.

Soup sets out to solve this by providing a single high performant system,
removing the need for manual materialization altogether. The current prototype
scales to millions of writes and reads per second \cite{soup}, and works both on
a single machine and in a distributed setting.

Soup does this by materializing data automatically in a data-flow
graph, building on existing streaming data-flow research \cite{naiad, dataflow}
by combining it with ideas from performant materialized view solutions
\cite{dbtoaster, pequod}.

\subsection{Data-flow Graph}
Soup turns base table schemas and a pre-defined list of queries into a data-flow
graph that doubles as a set of materialized views. The base tables form the
root nodes of the graph, and all writes propagate from here. The graph itself
resembles the query graph of a traditional relational database system
\cite{codd}, with the graph's intermediate nodes being relational operators.

However, whereas a relational database management system's query graph is used
primarily to retrieve data, by executing operators to fetch data from durable
storage, Soup's graph does the exact opposite. The graph is defined ahead of
queries being received, and writes stream through the relevant nodes in the
graph - starting from the base nodes. This skews the majority of the system's
work towards writes, as results are materialized at different nodes throughout
the graph.

The query graph includes at least one materialized node per pre-defined query,
located at the bottom of the graph as leaf nodes. This means that reading from
the system is a matter of finding the relevant leaf node, and retrieving data
from the node's materialized storage. This is one of the elements that makes Soup
resemble more of a key-vaule store than a traditional RDBMS. Even though Soup
supports advanced SQL queries, both mutations and retrievals are done with a
key, which then maps to a corresponding value.

On an elementary level one could see Soup creating a separate graph for each
query, similar to query graphs in traditional database systems, but that would
have been quite inefficient. For one it would have lead to Soup materializing a
lot of duplicate data for intermediary materialized nodes, and base table writes
would have had to be propagated to more nodes than necessary. Migrations would
also have taken considerably longer time, as adding queries would mean
constructing a completely new query graph. Instead Soup uses multi-query
optimization techniques to create common sub-graphs of nodes that can be used in
multiple queries.

\subsubsection{Domains}
Soup's data-flow graph is divided into logical domains, where each domain
contains a series of nodes. Within a domain, a single update is processed at a
time, removing the need for internal locks. Each domain is separated into a
different computational entity, either a thread, or a separate Soup client when
the system is run in a distributed fashion.

Domains are separated by ingress and egress nodes, where a boundary between
these are formed on the form of a buffered channel. In a multi-machine Soup
setup, the ingress and egress nodes are connected with TCP connections instead.

Note that domains do not handle read operations. These are served directly from
the leaf nodes by separate worker threads, maintaining high read performance
even in the midst of processing a large amount of writes.

\subsection{Architecture}
At the core of a running Soup system is the controller, which serves as the
initial entry point for communication with the rest of the Soup system. Clients
communicate with the controller over a TCP-based remote procedure call (RPC)
interface, exposing a series of building blocks that open for interaction with
the database. Two of the most central parts here are mutators and getters, which
allow respectively writing and reading from the data-flow graph. After getting a
hold of a mutator, clients perform writes and reads without going through the
controller. While this avoids the controller becoming a performance bottleneck,
the argument that the controller corresponds to a single failure point for a
distributed Soup still holds. The latest version of Soup improves this by making
controllers fault-tolerant, using ZooKeeper \cite{zookeeper} to implement
consensus.

\subsubsection{Souplets}
The actual work performed by a Soup system is done in Souplets, which
correspond to separate instances that communicate in a distributed fashion. Each
Souplet has a pool of workers, where domains are spread throughout the pool.
Previous implementations of Soup ran each domain in its own separate thread,
which led to reduced performance when the amount of domains went up in
core-constrained systems. A worker pool solves this by setting a cap on the
amount of threads that process domains, such that a single thread might be
responsible for processing packets for multiple domains.

Soup also supports running completely in one process, which is convenient for
local development and testing. In that case there is only a single worker pool,
which the controller is responsible for starting.

Communication between the Souplet instances and the controller is done over TCP,
in a layer that is referred to as the coordination plane. This involves
heartbeat messages, but also packets that are sent when domains are assigned,
re-assigned and removed to different Souplet instances.

\subsubsection{Backlog} \label{sec:readers}
Data written through mutators are sent through the data-flow graph, where they
eventually reach the leaf nodes: the readers. Here data is persisted into an
in-memory eventually consistent data structure, an \texttt{evmap} \cite{evmap}.
Getters then expose the records residing here by accessing the readers directly,
avoiding the need to go through the entire graph to retrieve data.
\texttt{evmap} implements reading without any locks at all, avoiding degrading
performance for read-heavy work loads.

\subsection{Materialization} \label{sec:materialization}
Similar to traditional relational databases, writes are inserted into the
table directly - a base node in Soup. Whereas this marks the end of the
operation for an RDBMS, Soup will continue by propagating the write throughout
the query graph, storing the result at materialized nodes.

The insertions are handled with a group-commit protocol, where records are
batched up and finally inserted into a durable log before being propagated to
the base node.

Soup primarily materializes leaf nodes in the graph, to enable fast read
queries. In some cases intermediary operators might also choose to materialize
the records they receive before they forward them through to their child nodes.
This is especially the case for stateful operators, such as extremum queries, as
these need to incrementally update their result - instead of having to go
through and re-calculate the state on every new record.

Nodes can also be partially materialized, which lets each node choose which rows
to keep in their internal state. This resembles a regular caching system, where
keys can be evicted after a period of inactivity.

\subsection{Migrations}
Relational databases require developers to pre-define a set of table schemas for
their application. Changes to these throughout a project's lifecycle are often
inevitable, however the process of performing migrations in a live
system without downtime is usually far from trivial \cite{stripe}. This is one
of the core issues Soup sets out to solve, by providing a database system that
lets developers change both the base table schemas and the pre-defined queries
at any point.

Soup constructs a new graph for added queries. This is done by finding overlaps
with the existing query graph nodes, to avoid duplicate materializations and
to reduce the amount of work done by each migration. Soup marks nodes as
partially materialized when possible, which lets the system start processing
requests for the newly defined query right away, by only fetching each key from
ancestor nodes when necessary. For fully materialized nodes, Soup will replay
all relevant base table writes from the closest materialized node. This
delays the point where Soup can start processing requests, but has the advantage
of not delaying subsequent requests to retrieve materializated keys later on.

Modifications to base table schemas are done in-place, by having Soup's base
nodes internally include the full history of columns for that specific table.
% TODO: default values

\subsection{Transactions}
An increasing amount of real-world database system users have found relaxed
consistency guarantees to be sufficient in the last few years, as it greatly
simplifies the problem of replicating large amounts of data across data centers
with high performance \cite{existential}. There are nonetheless without doubt
a wide variety of usecases for transactions, where the eventual consistency that
Soup offers is insufficient. To cater to these types of applications, Soup
allows developers to opt-in for transaction support, by defining their base
nodes as transactional.

Soup's transaction support is carefully designed to avoid slowing down
non-transactional workloads. Using optimistic concurrency control, Soup returns
timestamped tokens for reads, which can later be used to verify the validity of
the data that was read. Writes can only be performed at the end of a
transaction, when clients request their transactions to be committed. The
timestamp part of the token helps Soup validate if concurrent clients
interferred with the data, which lets the system notify the client by aborting
the ongoing transaction.

\subsection{Example} \label{example}
Having presented the different parts of the Soup system, lets look at how using
Soup currently works. The example in listing \ref{lst:soup-example} builds up a query
graph from scratch, then performs a few simple writes and reads to the running
instance.

The example simulates users voting on a series of different articles, and
includes two base tables: \texttt{Article} and \texttt{Vote}. It highlights the
use of two types of queries: internal and external. The former can be seen as a
helper for the latter, where only external queries are exposed to the user. The
output query in the example counts the number of votes for a specific article,
through a \texttt{JOIN} between the two tables.

\begin{listing}[H]
  \vspace*{-1.1in}
  \begin{minted}[frame=lines, linenos]{rust}
let sql = "
    # Base tables:
    CREATE TABLE Article (aid int, title varchar(255), \
                         url text, PRIMARY KEY(aid));
    CREATE TABLE Vote (aid int, uid int);

    # Internal query:
    VoteCount: SELECT Vote.aid, COUNT(uid) AS votes \
                FROM Vote GROUP BY Vote.aid;

    # External query (note the QUERY keyword):
    QUERY ArticleWithVoteCount: \
                SELECT Article.aid, title, url, VoteCount.votes AS votes \
                FROM Article, VoteCount \
                WHERE Article.aid = VoteCount.aid AND Article.aid = ?;";

// set up Soup via recipe
let mut blender = ControllerBuilder::default().build();
blender.install_recipe(sql.to_owned());

// Build the mutators and the getter:
let inputs = blender.inputs();
let outputs = blender.outputs();
let mut article_mutator = blender.get_mutator(inputs["Article"]).unwrap();
let mut vote_mutator = blender.get_mutator(inputs["Vote"]).unwrap();
let mut count_getter = blender
  .get_getter(outputs["ArticleWithVoteCount"])
  .unwrap();

// Create a new article:
let aid = 1;
let title = "test title";
let url = "http://pdos.csail.mit.edu";
article
    .put(vec![aid.into(), title.into(), url.into()])
    .unwrap();

// Then create a vote:
let uid = 1;
vote.put(vec![aid.into(), uid.into()]).unwrap();

// Finally, retrieve the vote count:
// (the second argument states that we want to block until the result is ready)
println!("Vote Count: {:?}", vote_count.lookup(&aid.into(), true))
  \end{minted}
  \caption{
    Writing to and reading from a Soup instance.
    \label{lst:soup-example}
  }
\end{listing}

\section{Recovery} \label{aries}
At the core of most database systems you will find a log manager, which
maintains a sequence of log records on disk. Logging is essential in maintaining
fault tolerancy and durability, and is used for a variety of issues: ensuring
the durability of committed data, recovering from failures, and rolling back
aborted transactions.

Even to this day one of the most popular algorithms for recovery is ARIES
\cite{aries} (Algorithm for Recovery and Isolation Exploitation Semantic), which
uses a write-ahead log to make sure that a persistent record of changes is
maintained before the actual changes themselves. Upon recovery ARIES makes sure
that all actions from the log prior to a crash are repeated (\textit{REDO}),
then reverts the operations belonging to failing transactions (\textit{UNDO}).
The former makes sure that durability is respected, while the latter maintains
atomicity.

Whereas the logging protocol used for recovery varies from implementation to
implementation, the principle behind a write-ahead log remains the same. By
maintaining a log of actions \textit{before} the changes themselves are made
durable, we make sure that we can recover from a potential crash. For
transactional systems we also maintain enough data to be able to achieve
atomicity for transactions.

\section{Recovery in Main-Memory Databases} \label{main-memory-recovery}
Accessing and writing to durable storage is consistently a bottleneck in
database storage systems. Even though database systems that rely on non-volatile
storage for durability can have large amounts of data available in RAM, writes
still have to be committed to persistent storage ahead of being made available
to clients. With the rise of hardware that is capable of storing entire
applications' datasets in their main memory, this is often seen as inefficient,
and has lead to an increase in so called main memory database systems.

As these main memory database systems rely on fast volatile storage as their
main data store, traditional techniques for maintaining ACID principles seem
unappealing. Almost all storage systems want to maintain some measure of
durability nonetheless however, which means that state needs to persisted to
durable storage at some point.

Taking periodic checkpoints of the entire system's state is one way of avoiding
total data loss in the event of a crash. Checkpointing used alone only achieves
partial durability however, as it is unfeasible to take a checkpoint after every
operation. Because of this some main memory systems also rely on so-called
K-safety, where data is replicated to K+1 replicas \cite{early-voltdb},
ensuring that the system could survive up to K failing nodes and still maintain
full durability. K-safety is because of this naturally sensitive to total
failures, where for example entire data centres fail.

A third alternative is maintaining a log of actions, which in VoltDB is referred
to as command logging \cite{voltdb-recovery}. Whereas a fine-grained system like
ARIES would log each individual modification, command logging would stick to
only persisting the actual SQL query, which could then later be re-executed.
This results in a significantly lower volume being logged, and a simpler
recovery process after failures. This is akin to the recovery system currently
being used in Soup, where each write request is logged with its corresponding
data.

With only a coarse-grained command log, recovery times would steadily increase
as an application gains more data, as all log entries would have to be processed
during recovery to reach the system's previous state. This is infeasible, and
systems like VoltDB opt for checkpointing as a way of minimizing the size of the
log that has to be replayed during recovery. VoltDB is not unique here though, and
a plethora of different checkpointing solutions exists in today's selection of
in-memory databases. As usual, there are trade-offs to be chosen between here
as well, however most systems seem to agree that performing the checkpoints in
an asynchronous manner, without blocking the system, is critical. This helps
achieve two key properties, as stated by \cite{memory-checkpoint}:

\begin{enumerate}
  \item Checkpointing should not significantly slow down the system's
    transactional throughput.
  \item Checkpointing should not introduce high amounts of latency to the
    system's regular processing.
\end{enumerate}

\section{Rust}
Rust \cite{rust} is an open-source systems programming language that guarantees memory
safety while maintaining a minimal runtime. Rust is sponsored by Mozilla, where
it is used to develop Servo - a completely new browser engine.

\begin{listing}
  \begin{minted}[frame=single]{rust}
fn main() {
  println!("Hello World!");
}
  \end{minted}
  \caption{Hello World in Rust}
\end{listing}

When choosing a language, developers are often forced to compromise between
higher level abstractions and performance. Large and latency sensitivy projects
like databases often opt for the latter through low-level languages like C,
which avoid expensive runtime safety checks. Rust removes this dilemma
altogether by providing developers with both the fine-tuned control and
performance they are used to in low-level languages, while offering abstractions
developers might be familiar with from interepretted languages.

One of Rust's key features is providing compile time safety both in terms of
types and memory. The latter is done through an ownership model which lets
developers program mostly without thinking about memory allocation and
deallocation, without the lowered performance of using something like a garbage
collector. Each variable in Rust is assigned one and only one owner, and the
variable is deallocated - or dropped - when that owner goes out of scope.

\chapter{Methodology}

\section{Logging in Soup}
Soup only logs entries from committed transactions, greatly simplifying the
recovery protocol. The log is written prior to entries being forwarded
through the query graph, which makes sure that all changes are persisted to disk
before being made accessible to the client. Soup does however make use of a
\textit{group-commit scheme} \cite{main-memory}, buffering up a series of
packets before finally incurring an I/O write to persist the group as one unit.

At the time of writing, Soup defaults to gathering up 256 operations before
flushing the group to disk, drastically increasing the throughput of the system.
Not only does this reduce the amount of I/O operations per request, merging the
data from multiple requests into a single unit also means less packets to feed
through the Soup query graph. The log entries themselves are JSON \cite{json}
serialized arrays of Soup's data types.

\subsection{Log based recovery}
While a persisted log of entries existed ahead of writing this thesis, use of
these logs for recovery purposes was yet to be implemented. While the final goal
of this project is snapshot based recovery, the first step was nonetheless to
implement the baseline: replaying the log.

In a traditional relational database management system, log recovery often comes
in multiple phases. Following a system such as ARIES, as described in section
\ref{aries}, log recovery is responsible for a wide variety of tasks, such as
making sure the work of aborted transactions is undone. Compared to this, log
recovery in Soup is fairly trivial. This comes as a result of the log being
highly granular, as it only includes the actual operations being done - not the
differences each operation results in for the database. There is no UNDO or REDO
either: only committed operations result in log entries being persisted.

Log recovery in Soup is because of this a matter of replaying the writes from
the persisted logs on start-up, by feeding them into the query graph's base
nodes as if they were regular updates. Each line in the log corresponds to a
packet that was once fed through the previously running Soup instance's query
graph, now serialized using JSON as shown in listing \ref{lst:log-entry}.

\begin{listing}[H]
  \begin{minted}{json}
[
  [{"Positive": [{"Int": 1}, {"Int": 0}]}],
  [{"Positive": [{"Int": 1}, {"Int": 1}]}],
  [{"Positive": [{"Int": 1}, {"Int": 2}]}]
]
  \end{minted}
  \caption{
    An expanded line from one of the log files of the example application from section
    \ref{example}, corresponding to a single batched update with three records.
    \label{lst:log-entry}
  }
\end{listing}

Log entries are separated by a newline character, where each line in the log
is valid JSON. This lets the recovery process handle one line at a time in a
buffered fashion, avoiding the need to read in the entire log in memory. Similar
to how the packets where created in the first place, individual updates from
each log entry are batched into chunks, before finally being turned into
separate packets that are passed on to the rest of the query graph. This speeds
up recovery performance by avoiding having to process a potentially large
amount of small log entries.

\begin{figure}[H]
  \includesvg[width=\textwidth]{log-chunking}
  \caption{
    Log entries are flattened, then chunked into individual packets.
    \label{log-chunking}
  }
\end{figure}

For transactional base nodes, a timestamp has to be taken for each packet
created by the recovery packet. This is done through a specific RPC request to the
checktable.

\section{Snapshotting}
While being able to replay log entries during recovery
gives Soup durability, it is far from a feasible option for a production level
database management system. With time, the log files would grow in an unbounded
fashion, resulting in constantly increasing recovery times for any long running
Soup system.

Checkpointing of the entire system's state is, as section
\ref{main-memory-recovery} describes, a common way to deal with this for
main-memory database systems. By creating a recoverable checkpoint of the
system's state, log entries prior to the checkpoint can be discarded, which
makes sure that the system's recovery time remains manageable.

Snapshotting a running Soup instance's entire state is not trivial however.
Main memory systems like VoltDB leverage checkpointing by persisting the
transactional state of commmitted transactions, using log sequence numbers to be
able to track which updates have been reflected on disk \cite{voltdb-recovery}.
In Soup, state is materialized at a variety of nodes throughout the query graph,
and updates have no timestamps or sequence numbers attached to them. Updates
also propagate through the graph asynchronously, and a specific update is likely
to reach different points in the graph at separate times. Taking a global
snapshot of the entire graph simulatenously would thus mean capturing nodes at
different logical points, as an update might be in the process of propagating
throughout the graph at the time that the snapshot is initiated.

In a way, the nature of Soup's update propagation through a query graph
resembles the communication done in a distributed system, where access to a
common clock is rare. Being able to observe the global state in such a
distributed system is an immensely useful property, and is crucial to resolving
problems such as deadlock detection.

Chandy and Lamport first introduced the problem of a distributed snapshot in
"Distributed Snapshots: Determining Global States of Distributed Systems"
\cite{chandy-lamport}, which has since been the inspiration for a wide variety
of work within the field. Chandy and Lamport presented a solution to be used in
a distributed system with preserved message ordering, using first-in first-out
channels. They resolved two main issues: deciding when to take a snapshot, and
selecting which messages should be a part of said snapshot.

The key insight in \cite{chandy-lamport} is to introduce a marker message, that
can be used as a separator between messages that should be included in a
snapshot, and messages that should not. Processes that receive a snapshot marker
should immediately take a snapshot of all messages received prior to the marker,
and forward the resulting state to a process capable of assembling all local
snapshots to a global view of the system. Because of the channels' FIFO
property, snapshots will not include messages that arrive after a marker at a
node. This results in a requirement of \textit{O(e)} messages to initiate a
snapshot, where \textit{e} signifies the amount of edges in the graph. Since
these messages can be sent out in parallel, the time to complete a snapshot is
\textit{O(d)}, where \textit{d} is the diameter of the graph.

Lai and Yang \cite{lai-yang} later extend this scheme with support for non-FIFO
channels, which obleviates the need for explicit control messages by piggy-backing
the required information onto existing messages.

\subsection{Snapshotting algorithm}
As mentioned above, snapshotting the state of a running Soup instance would mean
persisting the content of each materialized node in the system. This needs to be
done at the same logical point in time, ensuring that updates either
propagate to all nodes that are being snapshotted - or none of them, leading to
a consistent state after recovering from a failure. At the same time,
creating a snapshot should not slow down the system too much, and definitely not
stop the system from processing updates completely. From this we can derive a
few base rules for our snapshotting algorithm:

\begin{enumerate}
  \item Each node's snapshot needs to include exactly the same updates across
    the graph.
  \item Taking a snapshot of the system should not signifantly degrade its
    throughput.
  \item Snapshots should complete in a reasonable amount of time.
\end{enumerate}

Using these rules, we can build up a snapshotting algorithm in incremental
steps. Let us first consider a simple example that fails to meet the criteria
however. Figure \ref{bad-example} shows a running Soup instance, where an update
\texttt{A} is being propagated through the query graph. Ignoring the fact that
the snapshotting request would have to arrive simultaneously at both domains
from the controller, what would be the outcome if both the domains containing at
least one materialized node, shown with a blue color in the graph, would take
a snapshot at this very instant? Whereas the leftmost domain has had the time to
process update \texttt{A}, the rightmost one has not. The two domain are at
different \texttt{logical} points in time, meaning that the snapshot would fail
the first rule.

What would happen if the system instead waited until update A had gone through
the entire graph, before initiating a snapshot? This would follow the first
rule, while failing the second: no new updates could be served until the
snapshot has been taken across the entire graph.

\begin{figure}[H]
  \centering
  \includesvg[width=0.6\textwidth]{bad-example}
  \caption{
    A partial Soup query graph, where an update \texttt{A} propagates through
    the domains in the query graph in an asynchronous manner. Domains 2 and 3
    contain at least one materialized node, and should be snapshotted.
    \label{bad-example}
  }
\end{figure}

\subsubsection{Synchronous snapshotting}
Soup's query graph communicates over FIFO channels, which makes it possible to
rely on Chandy-Lamport's marker technique to signify which updates should be
considered a part of the snapshot. Domains that receive the snapshot marker
initiate the snapshot process immediately, without any further processing of
updates. This makes sure that our snapshotting algorithm follows the first rule,
even if snapshots are taken at different physical points in time.

\begin{figure}[H]
  \centering
  \includesvg[width=0.6\textwidth]{good-example}
  \caption{
    Similar to the partial query graph in figure \ref{bad-example}, an update
    \texttt{A} is propating through the graph. This time it is followed by a
    snapshot marker however, which makes sure that domains with materialized
    nodes only snapshot when they receive the marker.
    \label{good-example}
  }
\end{figure}

The controller can then choose to take a snapshot of the entire graph by issuing
a snapshot marker to its base nodes, \texttt{TakeSnapshot}, which is propagated
through the rest of the graph. The controller keeps track of the current
\texttt{snapshot\_id} by writing it to persistent storage after a snapshot
completes, making sure that it can tell each domain which snapshot it should
recover from after a failure.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
InitializeSnapshot:
  snapshot_id += 1
  for node in base_nodes
    node.send(TakeSnapshot, snapshot_id)

  for node in base_nodes
    node.wait_for_ack()

  persist(snapshot_id)
  \end{minted}

  \caption{Initating a snapshot from the controller.}
\end{listing}

Domains that receive the snapshop marker proceed to initialize the
snapshotting process. After persisting a snapshot, the nodes notify the
controller that they have done so, letting it eventually discard log entries
when it has confirmed that all materialized nodes have created a snapshot with
id \texttt{snapshot\_id}. Implemented naively, this could involve simply
serializing each node's state at a domain, then persisting these to disk, while
blocking updates from the rest of the system - as shown in listing
\ref{naive-algo}.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
TakeSnapshot:
  for node in nodes
    if node.is_materialized
      state = serialize(node.state)
      write(state)
      notify_controller(snapshot_id)
  \end{minted}
  \caption{
    Naive beginning of a snapshot implementation for domains.
    \label{naive-algo}
  }
\end{listing}

\subsubsection{Asynchronous snapshotting} \label{sec:async-snapshot}
This would fulfill the properties of Chandy-Lamport's method and follow our
first snapshotting rule, as each domain stops processing updates until it has
completed taking a snapshot. On the other hand, writing to persistent storage is
far from fast, and following the snapshot method in listing \ref{naive-algo}
would mean a stop to domains' further update processing while snapshotting,
slowing down the system's throughput. To combat this, we would need to complete
the snapshotting in a separate computational unit, such as a thread, allowing
the domain to continue with its regular processing. The algorithm shown in
listing \ref{async-snapshot} does this by introducing a \texttt{SnapshotWorker},
which processes snapshot requests sent by domains.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
SnapshotWorker:
  for event in listener
      state = serialize(event.state)
      write(state)
      notify_controller(event.snapshot_id, event.state)

TakeSnapshotAsync:
  states = {}
  for node in nodes
    if node.is_materialized
      states[node] = node.state.clone()

  snapshot_worker.send(snapshot_id, states)
  \end{minted}
  \caption{
    Serializing and persisting snapshots in a separate computational unit, a
    \texttt{SnapshotWorker}.
    \label{async-snapshot}
  }
\end{listing}

\subsubsection{Delayed snapshotting}
Now the domain only needs to block while performing a clone of its nodes' state
- an improvement. At this point our algorithm still creates snapshots at roughly
the same point across the graph however, which means that the load induced by
taking a snapshot will be spread across the entire query graph. Comparing the
synchronous snapshotting algorithm to the asynchronous one, the amount of work
being done across the graph is far more in the former than the latter. With
snapshotting happening locally in domains, the work is done in parallel across
separate domains, whereas with a few snapshot workers each snapshot request is
processed synchronously. This introduces a trade-off between snapshot completion
time, and the load it puts on the system. However, long as each snapshot completes
before it is time to start a new one, avoiding a potential performance hit to
the system is far more crucial than being able to take snapshots quickly.

To further reduce the impact taking a snapshot has on the system's throughput,
each node could choose to delay the snapshot process by some amount of time.
This would ensure that different domains do as little as possible when receiving
a snapshot marker. Snapshots would still need to happen at \textit{logically} the same
time, but not in the same \textit{physical} instant across the graph. Simply
delaying the snapshotting locally at a domain would fail to uphold the former
however, as processing further updates would mean snapshotting at a different
logical time. Cloning the state when the snapshot marker arrives would naturally
solve this, while not getting us any further from the algorithm in listing
\ref{async-snapshot}.

A clone of the domain's state has to be taken at some point however, but
preferrably later than when the snapshot marker arrives. To do so we would need
to be able to go back from a state $ S_m $ to the original state when the marker
arrived, $ S_n $. With $ L_{n..m} $ signifying the updates that arrived from $ n
$ to $ m $, $ S_n $ can be re-created through $ S_m - L_{n..m} $. This lets
individual nodes delay initializing the snapshot process, preventing a global
performance hit to the system. The amount of work being done by a single domain
would be higher, as the domain would have to keep track of updates $ L_{n..m} $,
however the work itself would be spread out over a longer period.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
TakeSnapshotDelayed:
  states = {}
  for node in nodes
    if node.is_materialized
      current_state = node.state.clone()
      states[node] = current_state - processed_updates[node]

  snapshot_worker.send(snapshot_id, states)
  \end{minted}
  \caption{
    A delayed implementation of \texttt{TakeSnapshotAsync} from listing
    \ref{async-snapshot}. Updates after the marker arrived would need to be stored
    in \texttt{processed\_updates}.
  }
\end{listing}

\subsubsection{Snapshot confirmations}
When a node in the graph eventually snapshots its state, the controller should
be notified of its completion, as shown in \texttt{SnapshotWorker} from listing
\ref{async-snapshot}. The snapshots are already persisted to disk, so including
the actual data in these messages are unneccessary. They should on the other
hand include an identifier to the current snapshot request, so that the system
eventually knows when the entire graph has performed the same snapshot. At that
point the identifier of the snapshot can be persisted to disk, and the log
entries prior to the snapshot being taken can eventually be discarded.
Recovery is then a matter of first loading each materialized node's state from
their local snapshot, then replaying the rest of the log entries available.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
ReceiveSnapshotAck(domain_id, snapshot_id):
  snapshot_ids[domain_id] = snapshot_id
  if min(snapshot_ids) == snapshot_id
    persist_snapshot_id(snapshot_id)
  \end{minted}
  \caption{
    The controller listens for snapshot acknowledgments from snapshot
    workers, updating an internal data structure with a mapping from domain to
    \texttt{snapshot\_id} on each received confirmation. When all domains have
    snapshotted, the controller persists the \texttt{snapshot\_id}, so that it
    later on can be used for recovery.
    \label{snapshot_acks}
  }
\end{listing}

\subsubsection{Failure before discarding the log}
% TODO: this section is bad
In the event of a failure \textit{after} the controller has persisted the
snapshot ID to disk, but \textit{before} all nodes have managed to discard the
correct log entries from durable storage, duplicate replaying of those log
entries upon recovery is a possibility.

To prevent this from happening, each log
entry should include the last snapshot ID the domain successfully discarded.
While recovering, log entries that existed before the latest snapshot can then be
ignored. This is possible because the system is certain that each domain has an
available persisted snapshot at this point, as it would not have told it to
discard log entries otherwise.

\section{Implementing snapshotting in Soup}
The previous sections described the need for snapshotting as an addition to log
based recovery in Soup, and outlined a few viable algorithms for doing so. This
section highlights the actual snapshotting implementation that was developed
during this thesis, and a few of the choices that were made throughout the
process.

The implementation roughly follows along the lines of the asynchronous
snapshotting algorithm described in section \ref{sec:async-snapshot}. The
controller initiates snapshots through a specific marker, domains process
snapshots by cloning their nodes' state, and a snapshot worker is responsible
for serialization and persisting of the snapshots, followed by notifying the
controller of each domain's snapshot completion.

\subsection{Initializing a snapshot} \label{sec:snapshot-init}
\begin{wrapfigure}{r}{0.5\textwidth}
  \begin{center}
    \includesvg[width=0.4\textwidth]{take-snapshot}
    \caption{
      Snapshots are initialized when the controller sends a
      \texttt{TakeSnapshot} packet, and forwarded through the query graph by
      each domain. \label{fig:take-snapshot}
    }
  \end{center}
\end{wrapfigure}

Snapshots are initialized by the Soup controller using a special marker packet,
\texttt{TakeSnapshot}. This happens at a regular interval, as defined by the
configuration option \texttt{snapshot\_timeout}. The Soup controller processes
events in a single event loop, and a snapshot is triggered by emitting an
event to this internal loop. This is done from a separate snapshotting thread,
which sleeps until it is time to take a snapshot.

When the controller's main loop receives a request to trigger a snapshot, it
first makes sure that it has received all confirmations from the previous
snapshot before continuing. After doing so it increments its
\texttt{snapshot\_id}, and fires off a \texttt{TakeSnapshot} packet to each of
the base node domains in its query graph. Finally, it finishes, without waiting
for replies or confirmations from the domains it requested a snapshot of.

\subsection{Snapshotting at domains}
Whenever a domain receives a \texttt{TakeSnapshot} packet, it creates a cloned
copy of each of its materialized nodes' states. As shown in
\ref{fig:take-snapshot}, each domain then forwards the snapshotting packet on to
its children in the query graph, ensuring that each materialized node eventually
gets snapshotted. Finally, it sends the cloned states to its
\texttt{SnapshotWorker}, by issuing a \texttt{PersistSnapshotRequest}.

Forwarding of the \texttt{TakeSnapshot} packet by individual domains are done
through the egress nodes. Taking figure \ref{fig:take-snapshot} as an example,
domain A and C would be connected by respectively one egress node, in domain A,
and one ingress node, in domain C. As each domain runs in a separate
computational unit, the snapshot method in domain A will be able to finish even
if domain C has not.

\subsubsection{Snapshotting readers}
The snapshotting algorithm describes persisting the state of materialized nodes.
Although that is true, reality is slightly more nuanced. Materialized nodes in
Soup can be both internal and external, where the latter is represented through
readers, as discussed briefly in section \ref{sec:readers}. Both the internally
materialized nodes, and the readers, can as section \ref{sec:materialization}
states be both partially and fully materialized, meaning that a read request
might refer upwards to its ancestors nodes to fulfill a query it does not have
materialized state for. This does not make too much of a difference for the
snapshotting algorithm however, as we snapshot partially and fully materialized
nodes in the same way.

The state of readers and internal nodes are on the other hand represented
differently in the system, which means they need to be snapshotted and recovered
from in slightly different ways.

\subsection{Performing snapshot requests}
While each domain is responsible for gathering up the cloned copies of state
needed to eventaully recover from a failure, the actual serialization and
persisting of snapshots happens in separate snapshot workers. The current
implementation runs one of these per worker pool, resulting in one thread
per running Soup instance. This could be increased as needed, but it is
favorable that snapshots happen over a longer time to prevent reducing the
system's throughput during the snapshotting process.

When a domain has finished cloning the state of its materialized nodes, it
notifies its local snapshot worker through an asynchronous and unbounded
buffered \texttt{channel} \cite{rust-channels}. This ensures that snapshot
processing can happen separately, without having to block the domain's regular
workload. The snapshot worker receives \texttt{PersistSnapshotRequest} events
one by one, and processes them synchronously. This involves serializing the
cloned state, persisting it to disk, and finally notifying the controller of a
domain's snapshot completion.

\subsection{Receiving snapshot confirmations}
The controller listens for snapshot confirmations on a TCP socket normally used
for coordination messages between the controller and its individual Souplet
workers. Whenever it receives an acknowledgement packet from a snapshot worker,
it stores the given \texttt{snapshot\_id} in a \texttt{HashMap} mapping each
domain that contains at least one materialized node to their current snapshot
ID. Note that domains can be sharded, so each instance in the map represents an
individual shard of a single domain.

When each shard has completed its snapshot, the current \texttt{snapshot\_id} is
persisted to disk, allowing the next snapshot to be initiated as described in
section \ref{sec:snapshot-init}.

\chapter{Results}

\chapter{Discussion}
\section{Future work}
\section{Conclusion}

\bibliographystyle{acm}
\bibliography{sources}

\end{document}
