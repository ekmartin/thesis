\documentclass[b5paper]{report}

\usepackage{color}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{float}
\usepackage{url}
\usepackage[chapter]{minted}

\graphicspath{{images/}}
\svgpath{{/Users/ek/Code/semester/images/}}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,decorations,shadows}

\begin{document}
\title{Efficient recovery in a data-flow based storage system}
\author{Martin Ek}
\date{\today}
\maketitle

\input{macros.tex}

\begin{abstract}
  Abstract
\end{abstract}

\tableofcontents
\pagebreak

\chapter{Introduction}
Soup is a high-performance database system developed at the Parallel and
Distributed Operating System group at MIT CSAIL. Soup builds up and maintains a
data-flow graph, avoiding the need to manually maintain materialized views. By
adapting the graph to schema changes on-the-fly, Soup avoids the substantial
downtime that comes with migrations in traditional relational database
management systems.

Utilizing a group-commit protocol, Soup persists all base table writes to
a log on durable storage before propagating changes throughout the graph.
Recovery is based on replaying the semantic updates in this log, which naturally
leads to gradually increasing recovery times as a database acquires more data.
Checkpointing by taking a snapshot of the database's current state is a common
way to solve this issue, reducing the size of the log at the same time. This is
not trivial in Soup however, where the data is spread across materializations in
the data-flow graph, and updates are propagated through asynchronously without
timestamps.

This thesis approaches the problem of creating a logically consistent snapshot
across Soup's data-flow graph by comparing it to a distributed system, where
each node in the graph can be seen as a node in a distributed setting. Soup as a
system is introduced in Chapter 2, whereas Chapter 3 looks at and compares
recovery solutions in different database systems before going into more detail
regarding Soup's solution for recovery. Then, various solutions for
snapshotting in distributed systems are investigated, while parallels to Soup's
own data-flow graph are drawn. Finally, a method for snapshotting in Soup is
proposed, implemented and compared to the baseline of only log based recovery.

\chapter{Background}
\section{Soup}
Modern web applications face an increasingly difficult performance problem in
relation to their storage needs: traditional relational databases perform too
poorly when used in isolation. Either by failing to scale to a large amount of
concurrent users, or by taking too long to return results for more expensive
aggregation queries.

This is often worked around by building up intricate cache hierarchies
\cite{memcached}, similar to the multi-level cache hierarchy readers might be
accustomed to seeing in their processors. This solves both performance problems:
concurrent readers can access materialized data from the upper levels of the
cache hierarchy, achieving low latency and high throughput even when faced with
large amounts of clients. Expensive queries then only need to be performed once,
as long as the result is invalidated when the underlying data changes. Write
operations still need to change the underlying storage layer however, but are
now also responsible for clearing out or updating the materialized cache levels.

This adds an extra layer of complexity, and is a trade-off accepted by almost
every modern day developer that faces more than a trivial amount of load to
their storage system.

Soup sets out to solve this by providing a single high performant system,
removing the need for manual materialization altogether. The current prototype
scales to millions of writes and reads per second \cite{soup}, and works both on
a single machine and in a distributed setting.

Soup does this by materializing data automatically in a data-flow
graph, building on existing streaming data-flow research \cite{naiad, dataflow}
by combining it with ideas from performant materialized view solutions
\cite{dbtoaster, pequod}.

\subsection{Data-flow Graph}
Soup turns base table schemas and a pre-defined list of queries into a data-flow
graph that doubles as a set of materialized views. The base tables form the
root nodes of the graph, and all writes propagate from here. The graph itself
resembles the query graph of a traditional relational database system
\cite{codd}, with the graph's intermediate nodes being relational operators.

However, whereas a relational database management system's query graph is used
primarily to retrieve data, by executing operators to fetch data from durable
storage, Soup's graph does the exact opposite. The graph is defined ahead of
queries being received, and writes stream through the relevant nodes in the
graph - starting from the base nodes. This skews the majority of the system's
work towards writes, as results are materialized at different nodes throughout
the graph.

The query graph includes at least one materialized node per pre-defined query,
located at the bottom of the graph as leaf nodes. This means that reading from
the system is a matter of finding the relevant leaf node, and retrieving data
from the node's materialized storage. This is one of the elements that makes Soup
resemble more of a key-vaule store than a traditional RDBMS. Even though Soup
supports advanced SQL queries, both mutations and retrievals are done with a
key, which then maps to a corresponding value.

On an elementary level one could see Soup creating a separate graph for each
query, similar to query graphs in traditional database systems, but that would
have been quite inefficient. For one it would have lead to Soup materializing a
lot of duplicate data for intermediary materialized nodes, and base table writes
would have had to be propagated to more nodes than necessary. Migrations would
also have taken considerably longer time, as adding queries would mean
constructing a completely new query graph. Instead Soup uses multi-query
optimization techniques to create common sub-graphs of nodes that can be used in
multiple queries.

\subsubsection{Domains}
Soup's data-flow graph is divided into logical domains, where each domain
contains a series of nodes. Within a domain, a single update is processed at a
time, removing the need for internal locks. Each domain is separated into a
different computational entity, either a thread, or a separate Soup client when
the system is run in a distributed fashion.

Domains are separated by ingress and egress nodes, where a boundary between
these are formed on the form of a buffered channel. In a multi-machine Soup
setup, the ingress and egress nodes are connected with TCP connections instead.

Note that domains do not handle read operations. These are served directly from
the leaf nodes by separate worker threads, maintaining high read performance
even in the midst of processing a large amount of writes.

\subsection{Architecture}
At the core of a running Soup system is the controller, which serves as the
initial entry point for communication with the rest of the Soup system. Clients
communicate with the controller over a TCP-based remote procedure call (RPC)
interface, exposing a series of building blocks that open for interaction with
the database. Two of the most central parts here are mutators and getters, which
allow respectively writing and reading from the data-flow graph. After getting a
hold of a mutator, clients perform writes and reads without going through the
controller. While this avoids the controller becoming a performance bottleneck,
the argument that the controller corresponds to a single failure point for a
distributed Soup still holds. The latest version of Soup improves this by making
controllers fault-tolerant, using ZooKeeper \cite{zookeeper} to implement
consensus.

\subsubsection{Souplets}
The actual work performed by a Soup system is done in Souplets, which
correspond to separate instances that communicate in a distributed fashion. Each
Souplet has a pool of workers, where domains are spread throughout the pool.
Previous implementations of Soup ran each domain in its own separate thread,
which led to reduced performance when the amount of domains went up in
core-constrained systems. A worker pool solves this by setting a cap on the
amount of threads that process domains, such that a single thread might be
responsible for processing packets for multiple domains.

Soup also supports running completely in one process, which is convenient for
local development and testing. In that case there is only a single worker pool,
which the controller is responsible for starting.

Communication between the Souplet instances and the controller is done over TCP,
in a layer that is referred to as the coordination plane. This involves
heartbeat messages, but also packets that are sent when domains are assigned,
re-assigned and removed to different Souplet instances.

\subsubsection{Backlog}
Data written through mutators are sent through the data-flow graph, where they
eventually reach the leaf nodes: the readers. Here data is persisted into an
in-memory eventually consistent data structure, an \texttt{evmap} \cite{evmap}.
Getters then expose the records residing here by accessing the readers directly,
avoiding the need to go through the entire graph to retrieve data.
\texttt{evmap} implements reading without any locks at all, avoiding degrading
performance for read-heavy work loads.

\subsection{Materialization}
Similar to traditional relational databases, writes are inserted into the
table directly - a base node in Soup. Whereas this marks the end of the
operation for an RDBMS, Soup will continue by propagating the write throughout
the query graph, storing the result at materialized nodes.

The insertions are handled with a group-commit protocol, where records are
batched up and finally inserted into a durable log before being propagated to
the base node.

Soup primarily materializes leaf nodes in the graph, to enable fast read
queries. In some cases intermediary operators might also choose to materialize
the records they receive before they forward them through to their child nodes.
This is especially the case for stateful operators, such as extremum queries, as
these need to incrementally update their result - instead of having to go
through and re-calculate the state on every new record.

Nodes can also be partially materialized, which lets each node choose which rows
to keep in their internal state. This resembles a regular caching system, where
keys can be evicted after a period of inactivity.

\subsection{Migrations}
Relational databases require developers to pre-define a set of table schemas for
their application. Changes to these throughout a project's lifecycle are often
inevitable, however the process of performing migrations in a live
system without downtime is usually far from trivial \cite{stripe}. This is one
of the core issues Soup sets out to solve, by providing a database system that
lets developers change both the base table schemas and the pre-defined queries
at any point.

Soup constructs a new graph for added queries. This is done by finding overlaps
with the existing query graph nodes, to avoid duplicate materializations and
to reduce the amount of work done by each migration. Soup marks nodes as
partially materialized when possible, which lets the system start processing
requests for the newly defined query right away, by only fetching each key from
ancestor nodes when necessary. For fully materialized nodes, Soup will replay
all relevant base table writes from the closest materialized node. This
delays the point where Soup can start processing requests, but has the advantage
of not delaying subsequent requests to retrieve materializated keys later on.

Modifications to base table schemas are done in-place, by having Soup's base
nodes internally include the full history of columns for that specific table.
% TODO: default values

\subsection{Transactions}
An increasing amount of real-world database system users have found relaxed
consistency guarantees to be sufficient in the last few years, as it greatly
simplifies the problem of replicating large amounts of data across data centers
with high performance \cite{existential}. There are nonetheless without doubt
a wide variety of usecases for transactions, where the eventual consistency that
Soup offers is insufficient. To cater to these types of applications, Soup
allows developers to opt-in for transaction support, by defining their base
nodes as transactional.

Soup's transaction support is carefully designed to avoid slowing down
non-transactional workloads. Using optimistic concurrency control, Soup returns
timestamped tokens for reads, which can later be used to verify the validity of
the data that was read. Writes can only be performed at the end of a
transaction, when clients request their transactions to be committed. The
timestamp part of the token helps Soup validate if concurrent clients
interferred with the data, which lets the system notify the client by aborting
the ongoing transaction.

\subsection{Example} \label{example}
Having presented the different parts of the Soup system, lets look at how using
Soup currently works. The example in listing \ref{lst:soup-example} builds up a query
graph from scratch, then performs a few simple writes and reads to the running
instance.

The example simulates users voting on a series of different articles, and
includes two base tables: \texttt{Article} and \texttt{Vote}. It highlights the
use of two types of queries: internal and external. The former can be seen as a
helper for the latter, where only external queries are exposed to the user. The
output query in the example counts the number of votes for a specific article,
through a \texttt{JOIN} between the two tables.

\begin{listing}[H]
  \vspace*{-1.1in}
  \begin{minted}[frame=lines, linenos]{rust}
let sql = "
    # Base tables:
    CREATE TABLE Article (aid int, title varchar(255), \
                         url text, PRIMARY KEY(aid));
    CREATE TABLE Vote (aid int, uid int);

    # Internal query:
    VoteCount: SELECT Vote.aid, COUNT(uid) AS votes \
                FROM Vote GROUP BY Vote.aid;

    # External query (note the QUERY keyword):
    QUERY ArticleWithVoteCount: \
                SELECT Article.aid, title, url, VoteCount.votes AS votes \
                FROM Article, VoteCount \
                WHERE Article.aid = VoteCount.aid AND Article.aid = ?;";

// set up Soup via recipe
let mut blender = ControllerBuilder::default().build();
blender.install_recipe(sql.to_owned());

// Build the mutators and the getter:
let inputs = blender.inputs();
let outputs = blender.outputs();
let mut article_mutator = blender.get_mutator(inputs["Article"]).unwrap();
let mut vote_mutator = blender.get_mutator(inputs["Vote"]).unwrap();
let mut count_getter = blender
  .get_getter(outputs["ArticleWithVoteCount"])
  .unwrap();

// Create a new article:
let aid = 1;
let title = "test title";
let url = "http://pdos.csail.mit.edu";
article
    .put(vec![aid.into(), title.into(), url.into()])
    .unwrap();

// Then create a vote:
let uid = 1;
vote.put(vec![aid.into(), uid.into()]).unwrap();

// Finally, retrieve the vote count:
// (the second argument states that we want to block until the result is ready)
println!("Vote Count: {:?}", vote_count.lookup(&aid.into(), true))
  \end{minted}
  \caption{
    Writing to and reading from a Soup instance.
    \label{lst:soup-example}
  }
\end{listing}

\section{Recovery} \label{aries}
At the core of most database systems you will find a log manager, which
maintains a sequence of log records on disk. Logging is essential in maintaining
fault tolerancy and durability, and is used for a variety of issues: ensuring
the durability of committed data, recovering from failures, and rolling back
aborted transactions.

Even to this day one of the most popular algorithms for recovery is ARIES
\cite{aries} (Algorithm for Recovery and Isolation Exploitation Semantic), which
uses a write-ahead log to make sure that a persistent record of changes is
maintained before the actual changes themselves. Upon recovery ARIES makes sure
that all actions from the log prior to a crash are repeated (\textit{REDO}),
then reverts the operations belonging to failing transactions (\textit{UNDO}).
The former makes sure that durability is respected, while the latter maintains
atomicity.

Whereas the logging protocol used for recovery varies from implementation to
implementation, the principle behind a write-ahead log remains the same. By
maintaining a log of actions \textit{before} the changes themselves are made
durable, we make sure that we can recover from a potential crash. For
transactional systems we also maintain enough data to be able to achieve
atomicity for transactions.

\section{Recovery in Main-Memory Databases}
Accessing and writing to durable storage is consistently a bottleneck in
database storage systems. Even though database systems that rely on non-volatile
storage for durability can have large amounts of data available in RAM, writes
still have to be committed to persistent storage ahead of being made available
to clients. With the rise of hardware that is capable of storing entire
applications' datasets in their main memory, this is often seen as inefficient,
and has lead to an increase in so called main memory database systems.

As these main memory database systems rely on fast volatile storage as their
main data store, traditional techniques for maintaining ACID principles seem
unappealing. Almost all storage systems want to maintain some measure of
durability nonetheless however, which means that state needs to persisted to
durable storage at some point.

Taking periodic checkpoints of the entire system's state is one way of avoiding
total data loss in the event of a crash. Checkpointing used alone only achieves
partial durability however, as it is unfeasible to take a checkpoint after every
operation. Because of this some main memory systems also rely on so-called
K-safety, where data is replicated to K+1 replicas \cite{early-voltdb},
ensuring that the system could survive up to K failing nodes and still maintain
full durability. K-safety is because of this naturally sensitive to total
failures, where for example entire data centres fail.

A third alternative is maintaining a log of actions, which in VoltDB is referred
to as command logging \cite{voltdb-recovery}. Whereas a fine-grained system like
ARIES would log each individual modification, command logging would stick to
only persisting the actual SQL query, which could then later be re-executed.
This results in a significantly lower volume being logged, and a simpler
recovery process after failures. This is akin to the recovery system currently
being used in Soup, where each write request is logged with its corresponding
data.

With only a coarse-grained command log, recovery times would steadily increase
as an application gains more data, as all log entries would have to be processed
during recovery to reach the system's previous state. This is infeasible, and
systems like VoltDB opt for checkpointing as a way of minimizing the size of the
log that has to be replayed during recovery. VoltDB is not unique here though, and
a plethora of different checkpointing solutions exists in today's selection of
in-memory databases. As usual, there are trade-offs to be chosen between here
as well, however most systems seem to agree that performing the checkpoints in
an asynchronous manner, without blocking the system, is critical. This helps
achieve two key properties, as stated by \cite{memory-checkpoint}:

\begin{enumerate}
  \item Checkpointing should not significantly slow down the system's
    transactional throughput.
  \item Checkpointing should not introduce high amounts of latency to the
    system's regular processing.
\end{enumerate}

\chapter{Methodology}

\section{Logging in Soup}
Soup only logs entries from committed transactions, greatly simplifying the
recovery protocol. The log is written prior to entries being forwarded
through the query graph, which makes sure that all changes are persisted to disk
before being made accessible to the client. Soup does however make use of a
\textit{group-commit scheme} \cite{main-memory}, buffering up a series of
packets before finally incurring an I/O write to persist the group as one unit.

At the time of writing, Soup defaults to gathering up 256 operations before
flushing the group to disk, drastically increasing the throughput of the system.
Not only does this reduce the amount of I/O operations per request, merging the
data from multiple requests into a single unit also means less packets to feed
through the Soup query graph. The log entries themselves are JSON \cite{json}
serialized arrays of Soup's data types.

\subsection{Log based recovery}
While a persisted log of entries existed ahead of writing this thesis, use of
these logs for recovery purposes was yet to be implemented. While the final goal
of this project is snapshot based recovery, the first step was nonetheless to
implement the baseline: replaying the log.

In a traditional relational database management system, log recovery often comes
in multiple phases. Following a system such as ARIES, as described in section
\ref{aries}, log recovery is responsible for a wide variety of tasks, such as
making sure the work of aborted transactions is undone. Compared to this, log
recovery in Soup is fairly trivial. This comes as a result of the log being
highly granular, as it only includes the actual operations being done - not the
differences each operation results in for the database. There is no UNDO or REDO
either: only committed operations result in log entries being persisted.

Log recovery in Soup is because of this a matter of replaying the writes from
the persisted logs on start-up, by feeding them into the query graph's base
nodes as if they were regular updates. Each line in the log corresponds to a
packet that was once fed through the previously running Soup instance's query
graph, now serialized using JSON as shown in listing \ref{lst:log-entry}.

\begin{listing}[H]
  \begin{minted}{json}
[
  [{"Positive": [{"Int": 1}, {"Int": 0}]}],
  [{"Positive": [{"Int": 1}, {"Int": 1}]}],
  [{"Positive": [{"Int": 1}, {"Int": 2}]}]
]
  \end{minted}
  \caption{
    An expanded line from one of the log files of the example application from section
    \ref{example}, corresponding to a single batched update with three records.
    \label{lst:log-entry}
  }
\end{listing}

Log entries are separated by a newline character, where each line in the log
is valid JSON. This lets the recovery process handle one line at a time in a
buffered fashion, avoiding the need to read in the entire log in memory. Similar
to how the packets where created in the first place, individual updates from
each log entry are batched into chunks, before finally being turned into
separate packets that are passed on to the rest of the query graph. This speeds
up recovery performance by avoiding having to process a potentially large
amount of small log entries.

\begin{figure}
  % \includesvg[width=\textwidth]{log_chunking}
  \caption{
    Log entries are flattened, then chunked into individual packets.
    \label{log-chunking}
  }
\end{figure}

For transactional base nodes, a timestamp also has to be taken for each packet
created by the recovery packet. This is done through a specific RPC request to the
checktable.

\section{Snapshotting}
Snapshotting a running Soup instance's entire state is far from trivial.
Main memory systems like VoltDB leverage checkpointing by persisting the
transactional state of commmitted transactions, using log sequence numbers to be
able to track which updates have been reflected on disk. In Soup, state is
materialized at a variety of nodes throughout the query graph, and updates have no
timestamps or sequence numbers attached to them. Updates also propagate through
the graph asynchronously, and a specific update is likely to reach different
points in the graph at separate times. Taking a global snapshot of the entire
graph would thus mean capturing nodes at different logical points, as a write
might be in the process of propagating throughout the graph.

The nature of Soup's update propagation through a query graph resembles the
communication done in a distributed system, where access to a common clock is
rare. Being able to observe the global state in a distributed system is an
immensely useful property, and is crucial to resolving problems such as deadlock
detection.

Chandy and Lamport first introduced the problem of a distributed snapshot in
"Distributed Snapshots: Determining Global States of Distributed Systems"
\cite{chandy-lamport}, which has since been the inspiration for a wide variety
of work within the field. Chandy and Lamport presented a solution to be used in
a distributed system with preserved message ordering, using first-in first-out
channels. They resolved two main issues: deciding when to take a snapshot, and
selecting which messages should be a part of said snapshot.

The key insight in \cite{chandy-lamport} is to introduce a marker message, that
can be used as a separator between messages that should be included in a
snapshot, and messages that should not. Processes that receive a snapshot marker
should immediately take a snapshot of all messages received prior to the marker,
and forward the resulting state to a process capable of assembling all local
snapshots to a global view of the system. Because of the channels' FIFO
property, snapshots will not include messages that arrive after a marker at a
node. This results in a requirement of \textit{O(e)} messages to initiate a
snapshot, where \textit{e} signifies the amount of edges in the graph. Since
these messages can be sent out in parallel, the time to complete a snapshot is
\textit{O(d)}, where \textit{d} is the diameter of the graph.

Lai and Yang \cite{lai-yang} later extend this scheme with support for non-FIFO
channels, which obleviates the need for explicit control messages by piggy-backing
the required information onto existing messages.

\subsection{Snapshotting in Soup}
Soup's current recovery technique involves going through all log entries
available, and processing each individual entry as if it was a new write to the
system. Regardless of the recovery performance, the size of the log will
continue to grow with the lifetime of each Soup application. By introducing
snapshotting of materialized nodes, Soup would be able to discard a significant
part of the log at each snapshot, avoiding a continual growth in log size.

Soup's query graph communicates over FIFO channels, which makes it possible to
rely on Chandy-Lamport's marker technique to signify which updates should be
considered a part of the snapshot. To do so we introduce a \texttt{TakeSnapshot}
packet, which serves as the marker in the Chandy-Lamport algorithm. This marker
can then be propagated from the controller, to each of its base nodes, and then
throughout the rest of the graph.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
def initialize_snapshot(self):
  self.snapshot_id += 1
  for node in self.base_nodes:
    domain = node.domain()
    domain.send(packet::TakeSnapshot, snapshot_id)

  for node in self.nodes:
    domain = node.domain()
    domain.wait_for_acknowledge()
  \end{minted}

  \caption{Initating a snapshot from the controller}
\end{listing}

Domains that receive the \texttt{TakeSnapshot} packet proceed to initialize the
snapshotting process. After persisting a snapshot, the nodes notify the
controller that they have done so, letting it eventually discard log entries
when it has confirmed that all materialized nodes have created a snapshot with
id \texttt{snapshot\_id}. Implemented naively, this could involve simply
serializing each node's state at a domain, then persisting these to disk, while
blocking updates from the rest of the system:

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
def take_snapshot(self, snapshot_id):
  for node in self.nodes:
    if node.is_materialized:
      state = serialize(node.state)
      write(state)
      notify_controller(snapshot_id)
  \end{minted}
  \caption{Naive beginning of a snapshot implementation for domains}
\end{listing}

This would fulfill the properties of Chandy-Lamport's method, as each domain
stops processing messages until it has completed taking a snapshot. On the other
hand writing to persistent storage is far from fast, which means this would
undoubtedly slow down the throughput of the rest of the system. However, the
fact that the system has to snapshot the state at the exact logical moment the
marker is received does not mean that it has to persist the snapshot to disk at
the very same moment. An improvement to our initial \texttt{take\_snapshot}
attempt would then be to serialize the state synchronously, while writing the
snapshot to disk in a separate thread:

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
def take_snapshot(self, snapshot_id):
  for node in self.nodes:
    if node.is_materialized:
      state = serialize(node.state)
      thread:
        write(state)
        notify_controller(snapshot_id)
  \end{minted}
  \caption{Asynchronous snapshotting}
\end{listing}

\subsubsection{Delayed snapshotting}
Now the domain only needs to block while performing the state serialization - an
improvement. At this point our prototype still creates snapshots at roughly the
same point across the graph however, which means that we would block processing
at each domain containing materialized nodes when this happens. To address this
the system will need to ensure that different domains do as little as possible
when receiving a snapshot marker simultaneously, ensuring that snapshots happen
at \textit{logically} the same time, but not in the same \textit{physical}
instant.

The solution this thesis proposes is to maintain a buffered log of writes that
are received after the snapshot marker, letting the system re-create the state
at the point the snapshot marker was received. If the system's state at that
point is denoted as $ S_n $, and $ L_{n..m} $ signifies the updates received
from \textit{n} to \textit{m}, $ S_n $ can be re-created through
$ S_m - L_{n..m} $. This lets individual nodes delay initializing the snapshot
process, preventing a global performance hit to the system.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
def take_snapshot(self, snapshot_id):
  for node in self.nodes:
    if node.is_materialized:
      cloned_state = node.state.clone()
      logged_updates = self.logged_updates[node]
      for update in logged_updates:
        cloned_state.revert(update)

      write_snapshot(node, snapshot_id, cloned_state)
      notify_controller(snapshot_id)
  \end{minted}
  \caption{Delayed snapshotting}
\end{listing}

\subsubsection{Discarding log entries}
When a node in the graph eventually snapshots its state, the controller should
be notified of its completion. The snapshots are already persisted to disk, so
including the actual data in these messages are unneccessary. They should on the
other hand include an identifier to the current snapshot request, so that the
system eventually knows when the entire graph has performed the same snapshot.
At that point the identifier of the snapshot can be persisted to disk, while
simultaneously discarding the log prior to the snapshot.

This means that the controller has to maintain a list of which nodes it is still
waiting for snapshots from, ensuring that it only attempts to discard parts of
the log after all nodes have successfully persisted a snapshot. It is also
crucial that the controller persists the current snapshot ID \textit{before} it
tells the nodes to discard their log entries, ensuring that the system knows
which snapshot that should be used at the point of recovery.

\begin{listing}[H]
  \begin{minted}[frame=single]{python}
def receive_snapshot_ack(self, node_id, snapshot_id):
  self.node_snapshot_ids[node_id] = snapshot_id
  # Make sure we only "complete" a snapshot when all nodes
  # have persisted theirs:
  if min(self.node_snapshot_ids.values()) < self.snapshot_id:
    return

  persist_snapshot_id(snapshot_id)
  for node in self.base_nodes:
    domain = node.domain()
    domain.send(packet::DiscardLogs, snapshot_id)
  \end{minted}
  \caption{Controller callback for snapshot acknowledgments}
\end{listing}

Recovery is then a matter of first loading each materialized node's state from
their local snapshot, then replaying the rest of the log entries available.

\subsubsection{Failure before discarding the log}
In the event of a failure \textit{after} the controller has persisted the
snapshot ID to disk, but \textit{before} all nodes have managed to discard the
correct log entries from durable storage, duplicate replaying of those log
entries upon recovery is a possibility.

To prevent this from happening, each log
entry should include the last snapshot ID the domain successfully discarded.
When recovering log entries that existed before the latest snapshot can then be
ignored. This is possible because the system is certain that each domain has an
available persisted snapshot at this point, as it would not have told it to
discard log entries otherwise.

\section{Rust}
Rust \cite{rust} is an open-source systems programming language that guarantees memory
safety while maintaining a minimal runtime. Rust is sponsored by Mozilla, where
it is used to develop Servo - a completely new browser engine.

\begin{listing}
  \begin{minted}[frame=single]{rust}
fn main() {
  println!("Hello World!");
}
  \end{minted}
  \caption{Hello World in Rust}
\end{listing}

When choosing a language, developers are often forced to compromise between
higher level abstractions and performance. Large and latency sensitivy projects
like databases often opt for the latter through low-level languages like C,
which avoid expensive runtime safety checks. Rust removes this dilemma
altogether by providing developers with both the fine-tuned control and
performance they are used to in low-level languages, while offering abstractions
developers might be familiar with from interepretted languages.

One of Rust's key features is providing compile time safety both in terms of
types and memory. The latter is done through an ownership model which lets
developers program mostly without thinking about memory allocation and
deallocation, without the lowered performance of using something like a garbage
collector. Each variable in Rust is assigned one and only one owner, and the
variable is deallocated - or dropped - when that owner goes out of scope.


\chapter{Results}
\chapter{Discussion}

\bibliographystyle{acm}
\bibliography{sources}

\end{document}
